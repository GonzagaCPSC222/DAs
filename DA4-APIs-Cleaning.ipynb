{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CPSC 222](https://github.com/GonzagaCPSC222) Intro to Data Science\n",
    "[Gonzaga University](https://www.gonzaga.edu/)\n",
    "\n",
    "[Gina Sprint](http://cs.gonzaga.edu/faculty/sprint/)\n",
    "## DA4 APIs and Cleaning (75 pts)\n",
    "\n",
    "## Learner Objectives\n",
    "At the conclusion of this programming assignment, participants should be able to:\n",
    "* Use an API (application programming interface) to make requests for data\n",
    "* Parse JSON data\n",
    "* Clean data\n",
    " \n",
    "## Prerequisites\n",
    "Before starting this programming assignment, participants should be able to:\n",
    "* Utilize the Pandas library to\n",
    "    * Read/write data from/to a CSV\n",
    "    * Work with DataFrames and Series\n",
    "    * Aggregate data and compute summary statistics\n",
    "\n",
    "## Acknowledgments\n",
    "Content used in this assignment is based upon information in the following sources:\n",
    "* [Pandas website](http://pandas.pydata.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github Classroom Setup\n",
    "For this assignment, you will use GitHub Classroom to create a private code repositories to track code changes and submit your assignment. Open this DA4 link to accept the assignment and create a private repository for your assignment in Github classroom: https://classroom.github.com/a/DPe39_50\n",
    "\n",
    "Your repo, for example, will be named GonzagaCPSC222/da4-yourusername (where yourusername is your Github username). I highly recommend committing/pushing regularly so your work is always backed up. We will grade your most recent commit, even if that commit is after the due date (your work will be marked late if this is the case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming (45 pts)\n",
    "The dataset we are going to use is going to be downloaded by your code!! We are going to download weather data from the [MeteoStat API](https://dev.meteostat.net/). This weather data may be very useful for your project ðŸ˜Ž\n",
    "\n",
    "### Background\n",
    "Before you start working with any new API, you want to read the documentation. Take some time and poke around [MeteoStat's JSON API](https://dev.meteostat.net/api/#json-api). Specifically, look at:\n",
    "1. How to get an API key\n",
    "    1. Follow the instructions on the MeteoStat documentation which sends you to [RapidAPI](https://rapidapi.com/meteostat/api/meteostat/)\n",
    "    1. Sign up for a RapidAPI account (note: DO NOT enter a credit card, we will use the free tier)\n",
    "    1. Then go to https://rapidapi.com/meteostat/api/meteostat/ and click on the blue Open playground link in the left sidebar\n",
    "        1. Note: you may need to click a blue button towards the middle of the page that says: \"subscribe to test\"\n",
    "        1. You will find your API key as the value of the `X-RapidAPI-Key` key\n",
    "        1. Note: unlike MapBox API, this API key goes in the \"headers\" of a GET request. For example: \n",
    "            1. `headers = {\"x-rapidapi-key\": YOUR_API_KEY_HERE}`\n",
    "            1. `requests.get(url=url, headers=headers)`\n",
    "1. The [daily data endpoint](https://dev.meteostat.net/api/stations/daily.html)\n",
    "    1. This requires a weather station ID\n",
    "1. You can get a weather station ID from the [nearby stations endpoint](https://dev.meteostat.net/api/stations/nearby.html)\n",
    "    1. This requires a latitude and longitude\n",
    "    1. You can get latitude and longitude from an address (e.g. a city name, like \"spokane\") using forward geocoding\n",
    "    1. MapBox provides a [Geocoding API](https://docs.mapbox.com/api/search/geocoding/) to do forward geocoding ðŸ¤“\n",
    "\n",
    "### Tasks\n",
    "Write Python code in a main.py and a utils.py based on the MapBox and MeteoStat API documentation to do the following:\n",
    "1. Prompt the user for the name of a large city\n",
    "    1. If there are spaces in the name, replace them with +\n",
    "1. Using the user-entered city, make a request to MapBox to get the city's latitude and longitude\n",
    "    1. Use the API key we made in class for MapBox\n",
    "    1. Extract the city's latitude and longitude. Store these in variables.\n",
    "1. Using the latitude and longitude variables, make a request to MeteoStat to get the coordinates' station ID\n",
    "    1. Extract the city's weather station ID. Store this in a variable.\n",
    "1. Using your weather station ID variable, get daily weather data for the previous year (2024-02-24 through 2025-02-23)\n",
    "    1. Set the units to be imperial to get Fahrenheit instead of Celsius\n",
    "    1. Structure this data nicely into a pandas' DataFrame\n",
    "1. Write the DataFrame to a csv file using the filename convention: `<city name>_daily_weather.csv`\n",
    "1. Clean the DataFrame so there are no missing values\n",
    "    1. Note: you may need to explore different cities to find one with missing data to appropriately test your solution\n",
    "    1. Remove columns with more than 50% of data missing\n",
    "    1. Fill the remaining missing values\n",
    "        1. \"Middle\" values should be filled with linear interpolation (see the [`interpolate()` documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html#pandas.DataFrame.interpolate) documentation)\n",
    "        1. Since you can't interpolate the first or last values if they are missing, using backfilling and forward filling appropriately (see the  [`bfill()` documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.bfill.html) and [`ffill()` documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.ffill.html))\n",
    "1. Write the cleaned DataFrame to a csv file using the filename convention: `<city name>_daily_weather_cleaned.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus (5 pts)\n",
    "Visualize a city's weather data using a Matplotlib chart. Prompt the user for an attribute to visualize. Then, create a bar chart and save it to a png file using the filename convention: `<city name>_daily_<attribute>.png`. Your chart should have an appropriate title, x and y labels, and have nice monthly x-axis tick labels. For example:\n",
    "\n",
    "<img src=\"https://github.com/GonzagaCPSC222/DAs/raw/master/figures/spokane_daily_tavg.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Part 4 (15 pts)\n",
    "Search for APIs you are interested in and browse the available APIs at: https://github.com/public-apis/public-apis Find a **simple** API that is unauthenticated, or uses an authentication scheme that you are comfortable working with, and read its documentation. The API doesn't need to be fancy or related to your project (but great if it does!). Ultimately I just want you to get more practice with APIs.\n",
    "\n",
    "In a file called project_part4.py, describe the API (including a link to its documentation!!), identify an endpoint that you are going to make a get request for data to, make the request, parse the response, and either pretty-print the data (if it is short) or write it to a CSV file if it is long (include this CSV file in your repo). \n",
    "\n",
    "Have fun with this one!! See if there any APIs out there you might want to use with your project ðŸ˜€ Remember, we can join two datasets using pandas, we just need common attributes (think key/foreign key pairs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ethics (15 pts)\n",
    "Read Chapter 1 of [Weapons of Math Destruction](https://www.amazon.com/Weapons-Math-Destruction-Increases-Inequality/dp/0553418815) by Cathy O'Neil. This book is a NY Times bestseller, National Book Award longlist winner, and frequently mentioned as one of the top non-technical data science/big data books that everyone should read (here are a few lists: [kdnuggets](https://www.kdnuggets.com/2019/12/non-technical-reading-list-data-science.html), [dataquest](https://www.dataquest.io/blog/data-science-books/), [builtin](https://builtin.com/data-science/data-science-books), etc.). You don't need to purchase this book, unless you want a hard-copy or you want to read the whole thing. I'll post the sections we will read to Canvas under the appropriate module for the DA so they are not publicly available on Github/GDrive.\n",
    "\n",
    "Please read the chapter directly and resist the urge to use AI to summarize it. Also, while I don't mind if you use AI to work with you to brainstorm ideas, **please do not outsource your thinking and writing to AI**. If you do use AI in any capacity, you must cite your use of it.\n",
    "\n",
    "In a **PDF document called ethics.pdf**, provide your reflection on the following discussion points:\n",
    "1. O'Neill uses baseball as an example of a domain this has been \"long ruled by the gut\". Do you think such domains, like baseball, benefit from predictive models? Are there some domains that you think models should not be applied to? Or if models are already applied to such domains, do you wish they had not been applied? Explain your reasoning with examples.\n",
    "1. Based on your experience with social media (or the experiences of your friends/family/others), what models do you think are used in social media? Would you consider these models WMDs? Here are some questions from the chapter to help you form your answer: \"...is the model opaque, or even invisible?\", \"Does the model work against the subject's interests?\", \"In short, is it unfair?\", \"Does it damage or destroy lives?\", and \"...can it scale?\" Cite at least one source to support your claims.\n",
    "1. What else struck you about this chapter?\n",
    "\n",
    "Your reflection write-up should be written using full sentences and should be grammaticallly correct. Proof read your writing before you submit it!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting Assignments\n",
    "1. Turn in your assignment files via a Github Classroom repo. See the \"Github Classroom Setup\" section at the beginning of this document for details on how to do this.\n",
    "    1. Your repo should contain all of the files needed to run and test your solution (e.g. .py file(s), input files, etc.).\n",
    "    1. Double-check that this is the case by \"pretending to be the grader\": clone (or download a zip) your submission repo and run your code like when we grade it.\n",
    "1. Submit this DAâ€™s associated assignment in Canvas to mark your DA as \"done\" and ready for grading. We will then pull your Github repo and grade your DA as soon as possible. The date and time you submit the DA assignment in Canvas will be used for marking your assignment as \"late\" or \"on-time.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Guidelines\n",
    "This assignment is worth 75 points + 5 points bonus. Your assignment will be evaluated based on a successful execution using the Anaconda Python Distribution (Python v3.12) from command line (e.g., with `python main.py`) and adherence to the program requirements. We will grade according to the following criteria:\n",
    "* 10 pts for requesting/parsing a latitude/longitude based on a city entered by the user\n",
    "* 10 pts for requesting/parsing a weather station ID based on a city's latitude longitude\n",
    "* 10 pts for requesting daily weather data using the weather station ID\n",
    "* 10 pts for cleaning data appropriately and writing the weather data to CSV\n",
    "* 5 pts for adherence to course [coding standard](https://nbviewer.jupyter.org/github/GonzagaCPSC222/DAs/blob/master/Coding%20Standard.ipynb)\n",
    "* 15 pts for describing and using an API in project_part4.py\n",
    "* 15 pts for quality, clarity, and creativity in the data ethics write-up"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
