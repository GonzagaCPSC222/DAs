{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CPSC 222](https://github.com/GonzagaCPSC222) Intro to Data Science\n",
    "[Gonzaga University](https://www.gonzaga.edu/)\n",
    "\n",
    "[Gina Sprint](http://cs.gonzaga.edu/faculty/sprint/)\n",
    "## DA6 Stats (75 pts)\n",
    "\n",
    "## Learner Objectives\n",
    "At the conclusion of this programming assignment, participants should be able to:\n",
    "* Compute confidence intervals manually and using Python (e.g. NumPy, SciPy, and/or Pandas)\n",
    "* Perform hypothesis testing using t-tests manually and using Python (e.g. NumPy, SciPy, and/or Pandas)\n",
    " \n",
    "## Prerequisites\n",
    "Before starting this programming assignment, participants should be able to:\n",
    "* Use Jupyter Notebook to tell a data science story\n",
    "* Use pandas for data analysis\n",
    "* Use matplotlib to visualize data\n",
    "\n",
    "## Acknowledgments\n",
    "Content used in this assignment is based upon information in the following sources:\n",
    "* T. Call, E. Fox and G. Sprint, [\"Gamifying Software Engineering Tools to Motivate Computer Science Students to Start and Finish Programming Assignments Earlier,\"](https://ieeexplore.ieee.org/document/9403918) in IEEE Transactions on Education, vol. 64, no. 4, pp. 423-431, 2021, doi: 10.1109/TE.2021.3069945.\n",
    "* G. Sprint, [\"Social Networks and Large Language Models for Division I Basketball Game Winner Prediction,\"](https://ieeexplore.ieee.org/abstract/document/10535112) in IEEE Access, vol. 12, pp. 84774-84784, 2024, doi: 10.1109/ACCESS.2024.3403490.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github Classroom Setup\n",
    "For this assignment, you will use GitHub Classroom to create a private code repositories to track code changes and submit your assignment. Open this DA6 link to accept the assignment and create a private repository for your assignment in Github classroom: https://classroom.github.com/a/RG97N65X\n",
    "\n",
    "Your repo, for example, will be named GonzagaCPSC222/da6-yourusername (where yourusername is your Github username). I highly recommend committing/pushing regularly so your work is always backed up. We will grade your most recent commit, even if that commit is after the due date (your work will be marked late if this is the case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Stats Exercises (20 pts)\n",
    "In a Jupyter Notebook called CPSC122GitCommitStats.ipynb, we are going to compute several calculations on the following two samples of data, S1 and S2. S1 and S2 are the total number of Git commits each student made on their programming assignments (PA3-PA9) in CPSC 122-01 and CPSC 122-02 in Spring 2020, respectively:\n",
    "\n",
    "S1: 4, 44, 21, 45,  3, 43, 19, 36, 68, 63, 24, 39, 42, 45, 25, 20, 24, 31,  2, 25, 30, 31, 24, 16, 44  \n",
    "S2: 10, 22, 40, 58, 49, 64, 26, 57, 139, 49,  41, 66, 12, 40, 20, 67, 106, 4, 46, 4, 34, 12, 48, 11, 62  \n",
    "Note: There were 25 students in each section.  \n",
    "Note: Commit were summed per student and not per assignment to ensure independence within the sample.\n",
    "\n",
    "We are going to crunch some stats using this 122 data because it is real data we used in a real experiment (that was really published!!). To elaborate, we conducted an approved experiment where the S1 students were a \"control\" group and the S2 students were an \"experiment\" group. The S2 students used a fully automated gamification software tool we designed that encouraged them to complete assignments early (for more info on the tool and experiment, check out our paper I cited in the Acknowledgments section above). \n",
    "\n",
    "For each of the following, clearly show detailed work (like you would on paper) for your calculations in a Markdown cell (including typesetting any formulas you use with Latex). In the following cell, show the steps needed to calculate the stat with Python.\n",
    "1. (3 pts) S1 95% confidence interval for the population mean\n",
    "    1. Show detailed manual calculations for the margin of error\n",
    "1. (3 pts) S2 95% confidence interval for the population mean\n",
    "    1. Show detailed manual calculations for the margin of error\n",
    "1. (4 pts) Visualize both S1 and S2 confidence intervals on the same figure with Matplotlib. How you do this is up to you, so long as the mean and interval are clearly displayed.\n",
    "1. (5 pts) S2 One-sample, one-tailed t-test of the population mean\n",
    "    1. Use the t-test to test the following hypothesis: did the S2 students commit more than 28 times on average? That would be about 4 commits per assignment. Use a level of significance of 0.025.\n",
    "    1. Show detailed manual calculations for each step of the 5 step hypothesis testing approach\n",
    "    1. Check your work with Python (e.g. NumPy, SciPy, and/or Pandas) in a code cell following your manual calculations\n",
    "    1. Are the results from the confidence interval and the hypothesis testing consistent?\n",
    "1. (5 pts) S1 and S2 Two-sample, one-tailed t-test of the population means\n",
    "    1. Use the t-test to answer the following hypothesis: did the S2 students commit more on average than the S1 students? Use a level of significance of 0.05.\n",
    "    1. Show detailed manual calculations for each step of the 5 step hypothesis testing approach\n",
    "    1. Check your work with Python (e.g. NumPy, SciPy, and/or Pandas) in a code cell following your manual calculations\n",
    "    1. Note: I purposely chose this dataset and this t-test because its result is published in an IEEE journal!! Check out Table II in our paper: [*Gamifying Software Engineering Tools to Motivate Computer Science Students to Start and Finish Programming Assignments Earlier*](https://ieeexplore.ieee.org/document/9403918). To get the matching p-value result, you'll need to set `equal_var=False` in your `ttest_ind()` call. `equal_var=False` specifies the test should not assume equal population variance and therefore a modified t-test called Welch's t-test should be performed (see the [`ttest_ind()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html) documentation for more details). You'll see that Welch's t-test increases the p-value, thus reducing the likelihood of a [type I error](https://en.wikipedia.org/wiki/Type_I_and_type_II_errors) (mistakenly rejecting an actually true null hypothesis). \n",
    "    1. Note: only set `equal_var=False` for this problem to see how to recreate the result from the paper ðŸ¤“"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SciPy Hypothesis Testing Exercises (35 pts)\n",
    "In a Jupyter Notebook called SciPyHypoTests.ipynb, we are going to make statistical inferences using several datasets and hypothesis testing. For each of the following exercises, describe the problem, data, and how you know what type of hypothesis t-test to perform (e.g. one vs two-sampled, one vs two-tailed, independent vs dependent) Then, perform the 5 step hypothesis testing approach with interleaved Markdown and Python cells explaining and showing your work with SciPy (note that you do not need to show detailed steps for your calculations like in the previous exercises, but you do need to show how/where you computed relevant values for each of the 5 steps).\n",
    "1. (5 pts) Using your cleaned inpatient rehabilitation dataset from DA5, is the mean age of women who had a stroke greater than the mean age of men who had a stroke? Use a level of significance of 0.01.\n",
    "1. (5 pts) Download the ed_222.json and ed_322.json files from the DAs repo on Github: https://github.com/GonzagaCPSC222/DAs/blob/master/files. These JSON files contain the student activity from my CPSC 222 (Fall 2021) and CPSC 322 (Spring 2021) classes. Note that I have removed identifying information and shuffled the order of the students. The attributes include \"Views\", \"Questions\", \"Days Active\". Using this Ed dataset, determine if there is a difference in the number of days 222 students are active on Ed (e.g. \"Days Active\") compared to 322 students. Use a level of significance of 0.001.\n",
    "1. (5 pts) Download the circuit_trials.csv file from the DAs repo on Github: https://github.com/GonzagaCPSC222/DAs/blob/master/files. This CSV file contains circuit durations (in seconds) for 27 subjects. A circuit consisted of performing several tasks like standing up from a chair, walking, and loading into a vehicle. Each subject completed the circuit at two different points in time, one week apart, producing two trials, A and B. During the week between trials, subjects received therapy services to improve their ability to perform the circuit. Using this circuit dataset, is the mean circuit duration for subjects at trial B less than it was at trial A (meaning, did the subjects perform the circuit faster after one week of physical therapy)? Use a level of significance of 0.01.\n",
    "1. (5 pts) Download the GU_website_daily_visitors_2018-2022.csv from the DAs repo on Github: https://github.com/GonzagaCPSC222/DAs/blob/master/files. This file contains daily number of new or returning users to the GU website (thank you to Lyle in GU IT for sharing this with us!!). Was there an increase in new visitors to the GU website during March Madness in 2021 (this was the year Baylor beat Gonzaga in the championship 86-70 ðŸ˜•)? To answer this question, let's look at the GU website traffic during the 2 months prior to the tournament (Jan and Feb 2021) and the 2 months of the tournament (March and April 2021). Use a level of significance of 0.005.\n",
    "1. (5 pts) Download wcc_2022.csv and wcc_2023.csv from the DAs repo on Github: https://github.com/GonzagaCPSC222/DAs/blob/master/files. These files contain the number of tweets from the men's and women's teams in the WCC (West Coast Conference) during the 2022 and 2023 seasons. Using this datasets, did the WCC teams tweet more in 2023 than they did in 2022? Use a level of significance of 0.05.\n",
    "    * This question and the next use a subset of data from a large Twitter research project I carried out 2 years ago. For more info on the project, check out our paper I cited in the Acknowledgments section above and/or my [Github repo](https://github.com/gsprint23/DivisionIBasketballTwitter)\n",
    "1. (10 pts) Download mens_teams.csv and womens_teams.csv from the DAs repo on Github: https://github.com/GonzagaCPSC222/DAs/blob/master/files. These files contain account-level Twitter information for men's and women's D1 college basketball teams. Note that the data was pulled via the Twitter API and ESPN website in 2023, so the information represents a snapshot of the accounts at the time (and is therefore not representative of current account-level information). Using this dataset, what interesting statistical inferences and conclusions do you find? You can use data in one or both files to formulate your research question(s). Write up your approach and findings using data storytelling (e.g. narrative before and after code cells describing your experiment design for reproducibility, data visualization(s), write-up of key findings, etc.).\n",
    "\n",
    "Note: the code for the above exercises does not need to be modular (e.g. you don't need to write functions); however, a utility function for interpreting t-values and p-values would be helpful since it is used so frequently. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus (5 pts)\n",
    "Aggregate the daily GU website data to be monthly instead of daily. Then produce the monthly bar chart below. This is a \"grouped\" bar chart and [here](https://matplotlib.org/stable/gallery/lines_bars_and_markers/barchart.html) is a page in the Matplotlib documentation to help you get started. I'll note that I produced the chart below using [Seaborn](https://seaborn.pydata.org/index.html), which is a charting library built on top of Matplotlib. You are free to try using Seaborn to solve this problem if you'd like!\n",
    "\n",
    "![](https://github.com/GonzagaCPSC222/DAs/raw/master/figures/GU_website_monthly_visitors_2018-2022.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ethics (15 pts)\n",
    "Read the following description of A/B testing from [Wikipedia](https://en.wikipedia.org/wiki/A/B_testing): \n",
    ">A/B testing (also known as bucket testing or split-run testing) is a user experience research methodology.[1] A/B tests consist of a randomized experiment with two variants, A and B.[2][3][4] It includes application of statistical hypothesis testing or \"two-sample hypothesis testing\" as used in the field of statistics. A/B testing is a way to compare two versions of a single variable, typically by testing a subject's response to variant A against variant B, and determining which of the two variants is more effective.[5]\n",
    "\n",
    "Then, read this article on [The Morality of A/B Testing](https://techcrunch.com/2014/06/29/ethics-in-a-data-driven-world/)\n",
    "\n",
    "In a Jupyter Notebook called Ethics.ipynb, provide your reflection on the following discussion points:\n",
    "1. Do you believe Facebook should have provided users with an option to opt-out of its news feed study? Why or why not?\n",
    "1. In the Facebook case study, the author argues the line requiring consent was crossed because \"this experiment tried to directly sway emotions.\" Now, think of a different \"news feed\" you regularly use (besides Facebook). This could be another social media site, or it could something else, like a news source like Google News or Gonzaga's Morning Mail. Describe a general \"line\" that you would consider crossed if this \"news feed\" starting running experiments on you that you would want to be able to opt-out of. \n",
    "1. The statement 1) \"consent is worth adding a little complexity to the product\" reminded me the saying 2) \"increased security comes at the expense of usability.\" The latter adage (#2) is referring to the effects of digital security enhancements (like changing our passwords frequently or multi-factor authentication) on users. In both cases (#1 and #2), there is a compromise between the user and organization providing the software service. The organization wants to be successful, which I'll note is defined differently at different companies. As users, we want to use certain software, but sometimes we also \"need\" to use certain software, even if we don't want to. Can you think of a software example for each adage (#1 and #2) where you \"need\" to use the software, regardless of its complexity, usability, or invasiveness? Does this affect your likelihood to opt-out of a study if you were given the \"option\"?\n",
    "1. What else struck you about this article? Any thoughts on Facebook's recent name change to [Meta](https://about.facebook.com/meta)? For example, what does \"meta\" mean and why do you think they are changing their name to it?\n",
    "\n",
    "This write-up should be written using full sentences and should be grammatically correct. Proof read your writing before you submit it!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting Assignments\n",
    "1. Turn in your assignment files via a Github Classroom repo. See the \"Github Classroom Setup\" section at the beginning of this document for details on how to do this.\n",
    "    1. Your repo should contain all of the files needed to run and test your solution (e.g. .py file(s), input files, etc.).\n",
    "    1. Double-check that this is the case by \"pretending to be the grader\": clone (or download a zip) your submission repo and run your code like when we grade it.\n",
    "1. Submit this DAâ€™s associated assignment in Canvas to mark your DA as \"done\" and ready for grading. We will then pull your Github repo and grade your DA as soon as possible. The date and time you submit the DA assignment in Canvas will be used for marking your assignment as \"late\" or \"on-time.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Guidelines\n",
    "This assignment is worth 75 points + 5 points bonus. Your assignment will be evaluated based on a successful execution in Jupyter Lab (using the Anaconda Python Distribution v3.12) and adherence to the program requirements. We will grade according to the following criteria:\n",
    "* 20 pts for correct manual stats and clearly described hand calculations\n",
    "* 35 pts for correct stats and clearly described Python calculations\n",
    "* 5 pts for adherence to course [coding standard](https://nbviewer.jupyter.org/github/GonzagaCPSC222/DAs/blob/master/Coding%20Standard.ipynb)\n",
    "* 15 pts for quality, clarity, and creativity in the data ethics write-up"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
